{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:24:07.768451Z",
     "start_time": "2025-11-09T18:24:07.764546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:24:09.643266Z",
     "start_time": "2025-11-09T18:24:09.460864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file = \"data/fii-nn-2025-homework-2/extended_mnist_train.pkl\"\n",
    "test_file = \"data/fii-nn-2025-homework-2/extended_mnist_test.pkl\"\n",
    "\n",
    "with open(train_file, \"rb\") as fp:\n",
    "    train = pickle.load(fp)\n",
    "\n",
    "with open(test_file, \"rb\") as fp:\n",
    "    test = pickle.load(fp)"
   ],
   "id": "f71fae586c4dfa26",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:24:11.332684Z",
     "start_time": "2025-11-09T18:24:11.120040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for image, label in train:\n",
    "    train_data.append(image.flatten() / 255.0)\n",
    "    train_labels.append(label)\n"
   ],
   "id": "94424e5708c390ce",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:24:13.863341Z",
     "start_time": "2025-11-09T18:24:13.827185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data = []\n",
    "for image, label in test:\n",
    "    test_data.append(image.flatten() / 255.0)\n"
   ],
   "id": "41f2159fd2dc0f37",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:24:15.826343Z",
     "start_time": "2025-11-09T18:24:15.822890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "def relu_prime(z):\n",
    "    return (z > 0).astype(float)\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ],
   "id": "eadf2189cdcb03d3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:01:51.367664Z",
     "start_time": "2025-11-09T18:59:18.860888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = np.array(train_data)\n",
    "Y = np.array(train_labels)\n",
    "\n",
    "\n",
    "n_inputs = 784\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "dropout_rate = 0.5\n",
    "\n",
    "limit_W1 = np.sqrt(6 / (n_inputs + n_hidden))\n",
    "W1 = np.random.uniform(-limit_W1, limit_W1, (n_inputs, n_hidden))\n",
    "B1 = np.zeros(n_hidden)\n",
    "\n",
    "limit_W2 = np.sqrt(6 / (n_hidden + n_outputs))\n",
    "W2 = np.random.uniform(-limit_W2, limit_W2, (n_hidden, n_outputs))\n",
    "B2 = np.zeros(n_outputs)\n",
    "Y_binary = np.zeros((Y.shape[0], n_outputs))\n",
    "\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    Y_binary[:, i] = np.where(Y == i, 1, 0)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_shuffled = X[indices]\n",
    "    Y_shuffled = Y_binary[indices]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        X_batch =X_shuffled[i : i + batch_size]\n",
    "        Y_batch = Y_shuffled[i : i + batch_size]\n",
    "        dim_batch = X_batch.shape[0]\n",
    "\n",
    "        z1 = np.dot(X_batch, W1) + B1\n",
    "        a1 = relu(z1)\n",
    "\n",
    "        z2 = np.dot(a1, W2) + B2\n",
    "        a2 = softmax(z2)\n",
    "\n",
    "        dropout_mask = (np.random.rand(*a1.shape) > dropout_rate).astype(float)\n",
    "        a1 *= dropout_mask\n",
    "        a1 /= (1.0 - dropout_rate)\n",
    "\n",
    "        loss = -np.sum(Y_batch * np.log(a2 + 1e-9)) / dim_batch\n",
    "\n",
    "        d2 = a2 - Y_batch\n",
    "        dW2 = np.dot(a1.T, d2) / dim_batch\n",
    "        dB2 = np.sum(d2, axis=0) / dim_batch\n",
    "\n",
    "        d1_prop = np.dot(d2, W2.T)\n",
    "        d1 = d1_prop * relu_prime(z1)\n",
    "\n",
    "        d1 *= dropout_mask\n",
    "        d1 /= (1.0 - dropout_rate)\n",
    "\n",
    "        dW1 = np.dot(X_batch.T, d1) / dim_batch\n",
    "        dB1 = np.sum(d1, axis=0) / dim_batch\n",
    "\n",
    "        W2 -= lr * dW2\n",
    "        B2 -= lr * dB2\n",
    "        W1 -= lr * dW1\n",
    "        B1 -= lr * dB1\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    W = W2\n",
    "    B = B2\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total training time: {elapsed_time:.2f} seconds\")\n"
   ],
   "id": "d2f00c39e7167c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5210\n",
      "Epoch 10, Loss: 0.0294\n",
      "Epoch 20, Loss: 0.1611\n",
      "Epoch 30, Loss: 0.1129\n",
      "Epoch 40, Loss: 0.0494\n",
      "Epoch 50, Loss: 0.1395\n",
      "Epoch 60, Loss: 0.0696\n",
      "Epoch 70, Loss: 0.0448\n",
      "Epoch 80, Loss: 0.0461\n",
      "Epoch 90, Loss: 0.0165\n",
      "Epoch 99, Loss: 0.0927\n",
      "Total training time: 152.41 seconds\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:12:25.385290Z",
     "start_time": "2025-11-09T19:12:25.382486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(X_test, W1, B1, W2, B2):\n",
    "    z1 = np.dot(X_test, W1) + B1\n",
    "    a1 = relu(z1)\n",
    "\n",
    "    z2 = np.dot(a1, W2) + B2\n",
    "    P = softmax(z2)\n",
    "\n",
    "    return np.argmax(P, axis=1)"
   ],
   "id": "13d48ec1f6a6edc",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:12:29.136153Z",
     "start_time": "2025-11-09T19:12:29.088503Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = predict(test_data, W1, B1, W2, B2)\n",
   "id": "2e0054c7288f9ee0",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:12:33.005453Z",
     "start_time": "2025-11-09T19:12:32.986347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is how you prepare a submission for the competition\n",
    "predictions_csv = {\n",
    "    \"ID\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "for i, label in enumerate(predictions):\n",
    "    predictions_csv[\"ID\"].append(i)\n",
    "    predictions_csv[\"target\"].append(label)\n",
    "\n",
    "df = pd.DataFrame(predictions_csv)\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ],
   "id": "2bdc89fcd27495d9",
   "outputs": [],
   "execution_count": 67
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
